{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in the Browser\n",
    "\n",
    "In this notebook, we will show how to create a `.air` file to perform sentiment analysis in the browser using a neural network.  To do this, we will utilize the IMDB Movie Reviews dataset to build the initial model, prune the model using the `mann` package, and then package the model using the `aisquared` Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "For this notebook, the following dependencies are required:\n",
    "\n",
    "- `mann`\n",
    "- `aisquared`\n",
    "\n",
    "Both of these are available on [pypi](https://pypi.org) via `pip`.  The following cell also runs the commands to install these dependencies as well as imports them into the notebook environment, along with TensorFlow (which is a dependency of the `mann` package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mann\n",
    "! pip install aisquared\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import aisquared\n",
    "import mann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Now that the required packages have been installed and imported, it is time to create the sentiment analysis model.  To do this, we have to first download and preprocess the data, create the model, prune the model so that it can perform well in the browser, and then package the model in the `.air` format.  The following cells will go through an in-depth explanation of each of the steps in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "    num_words = 10000,\n",
    "    skip_top = 0,\n",
    "    start_char = 1,\n",
    "    oov_char = 2,\n",
    "    index_from = 3\n",
    ")\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train,\n",
    "    maxlen = 512,\n",
    "    padding = 'post',\n",
    "    truncating = 'post'\n",
    ")\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_test,\n",
    "    maxlen = 512,\n",
    "    padding = 'post',\n",
    "    truncating = 'post'\n",
    ")\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# Add 2 to each vocab value to ensure matching with the needed values\n",
    "vocab = {\n",
    "    k : v + 2 for k, v in vocab.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "input_layer = tf.keras.layers.Input(x_train.shape[1:])\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    10000,\n",
    "    4\n",
    ")(input_layer)\n",
    "x = tf.keras.layers.Flatten()(embedding_layer)\n",
    "for _ in range(5):\n",
    "    x = mann.layers.MaskedDense(1000, activation = 'relu')(x)\n",
    "output_layer = mann.layers.MaskedDense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(input_layer, output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the model and train it\n",
    "model = mann.utils.mask_model(\n",
    "    model,\n",
    "    50,\n",
    "    x = x_train[:1000],\n",
    "    y = y_train[:1000].reshape(-1, 1)\n",
    ")\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Create a pruning callback that will increase pruning rate as performance improves\n",
    "callback = mann.utils.ActiveSparsification(\n",
    "    performance_cutoff = 0.8,\n",
    "    starting_sparsification = 50\n",
    ")\n",
    "\n",
    "# Train the model with the sparsification callback\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train.reshape(-1,1),\n",
    "    epochs = 1000,\n",
    "    batch_size = 512,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2,\n",
    "    callbacks = [callback]\n",
    ")\n",
    "\n",
    "# Now that the model has been trained, convert all model layers to built-in TensorFlow layers\n",
    "model = mann.utils.remove_layer_masks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model performance\n",
    "preds = (model.predict(x_test) >= 0.5).astype(int)\n",
    "print('Model Performance on Test Data:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Save the model\n",
    "model.save('SentimentClassifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package the Model\n",
    "\n",
    "Now that the model has been created, we can package the model into a single `.air` file that enables integration into the browser.\n",
    "\n",
    "To perform this packaging, we will be utilizing the `aisquared` package `DocumentPredictor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisquared.base.DocumentPredictor(\n",
    "    model_path = 'SentimentClassifier.h5',\n",
    "    vocabulary = vocab,\n",
    "    sequence_length = 512,\n",
    "    name = 'SentimentClassifier',\n",
    "    label_map = ['Negative', 'Positive', 'Inconclusive'],\n",
    "    include_probability = True,\n",
    "    remove_punctuation = False,\n",
    "    max_vocab = 9999\n",
    ").compile()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
